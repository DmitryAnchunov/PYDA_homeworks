{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQFg6BDHKcc9"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/KEYPHRASE_EXTRACTION.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOqOdIKkECq1"
   },
   "source": [
    "# **Extract keyphrases from documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99Qqhw7sEFyx"
   },
   "source": [
    "You can look at the example outputs stored at the bottom of the notebook to see what the model can do, or enter your own inputs to transform in the \"Inputs\" section. Find more about this keyphrase extraction model in another notebook [here](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/9.Keyword_Extraction_YAKE.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX0gNZv8MRtQ"
   },
   "source": [
    "## 1. Colab setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuXQkGilKWu7"
   },
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-Nz_2A8Jos8",
    "outputId": "6a60e581-d509-404d-bcf0-92682729d346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: apt-get: command not found\n",
      "/bin/sh: apt-get: command not found\n",
      "java version \"1.8.0_271\"\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_271-b09)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.271-b09, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "! pip install --ignore-installed -q spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognize_entities_dl download started this may take some time.\n",
      "Approx size to download 159 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "#create or get Spark Session\n",
    "spark = sparknlp.start()\n",
    "sparknlp.version()\n",
    "spark.version\n",
    "#download, load, and annotate a text by pre-trained pipeline\n",
    "pipeline = PretrainedPipeline('recognize_entities_dl', 'en')\n",
    "result = pipeline.annotate('Harry Potter is a great movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vb1y9TT8Ke_U"
   },
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WGMK0q_IIO_I"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "# Import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Import SparkNLP\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "# Start Spark session\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYDxs7_CMtpf"
   },
   "source": [
    "## 2. Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLk2XcmDMwTI"
   },
   "source": [
    "Enter inputs as strings in this list. Later cells of the notebook will extract keyphrases from whatever inputs are entered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "c_L-3nRuM0d4"
   },
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    \"\"\"Extracting keywords from texts has become a challenge for individuals and organizations as the information grows in complexity and size. The need to automate this task so that text can be processed in a timely and adequate manner has led to the emergence of automatic keyword extraction tools. Yake is a novel feature-based system for multi-lingual keyword extraction, which supports texts of different sizes, domain or languages. Unlike other approaches, Yake does not rely on dictionaries nor thesauri, neither is trained against any corpora. Instead, it follows an unsupervised approach which builds upon features extracted from the text, making it thus applicable to documents written in different languages without the need for further knowledge. This can be beneficial for a large number of tasks and a plethora of situations where access to training corpora is either limited or restricted.\"\"\",\n",
    "    \"\"\"Iodine deficiency is a lack of the trace element iodine, an essential nutrient in the diet. It may result in metabolic problems such as goiter, sometimes as an endemic goiter as well as cretinism due to untreated congenital hypothyroidism, which results in developmental delays and other health problems. Iodine deficiency is an important global health issue, especially for fertile and pregnant women. It is also a preventable cause of intellectual disability.\n",
    "\n",
    "Iodine is an essential dietary mineral for neurodevelopment among offsprings and toddlers. The thyroid hormones thyroxine and triiodothyronine contain iodine. In areas where there is little iodine in the diet, typically remote inland areas where no marine foods are eaten, iodine deficiency is common. It is also common in mountainous regions of the world where food is grown in iodine-poor soil.\n",
    "\n",
    "Prevention includes adding small amounts of iodine to table salt, a product known as iodized salt. Iodine compounds have also been added to other foodstuffs, such as flour, water and milk, in areas of deficiency. Seafood is also a well known source of iodine.\"\"\",\n",
    "    \"\"\"The Prague Quadrennial of Performance Design and Space was established in 1967 to bring the best of design for performance, scenography, and theatre architecture to the front line of cultural activities to be experienced by professional and emerging artists as well as the general public. The quadrennial exhibitions, festivals, and educational programs act as a global catalyst of creative progress by encouraging experimentation, networking, innovation, and future collaborations. PQ aims to honor, empower and celebrate the work of designers, artists and architects while inspiring and educating audiences, who are the most essential element of any live performance. The Prague Quadrennial strives to present performance design as an art form concerned with creation of active performance environments, that are far beyond merely decorative or beautiful, but emotionally charged, where design can become a quest, a question, an argument, a threat, a resolution, an agent of change, or a provocation. Performance design is a collaborative field where designers mix, fuse and blur the lines between multiple artistic disciplines to search for new approaches and new visions.\n",
    "\n",
    "The Prague Quadrennial organizes an expansive program of international projects and activities between the main quadrennial events – performances, exhibitions, symposia, workshops, residencies, and educational initiatives serve as an international platform for exploring the practice, theory and education of contemporary performance design in the most encompassing terms.\"\"\",\n",
    "    \"\"\"Author Nathan Wiseman-Trowse explained that the \"approach to the sheer physicality of sound\" integral to dream pop was \"arguably pioneered in popular music by figures such as Phil Spector and Brian Wilson\". The music of the Velvet Underground in the 1960s and 1970s, which experimented with repetition, tone, and texture over conventional song structure, was also an important touchstone in the genre's development George Harrison's 1970 album All Things Must Pass, with its Spector-produced Wall of Sound and fluid arrangements, led music journalist John Bergstrom to credit it as a progenitor of the genre.\n",
    "\n",
    "Reynolds described dream pop bands as \"a wave of hazy neo-psychedelic groups\", noting the influence of the \"ethereal soundscapes\" of bands such as Cocteau Twins. Rolling Stone's Kory Grow described \"modern dream pop\" as originating with the early 1980s work of Cocteau Twins and their contemporaries, while PopMatters' AJ Ramirez noted an evolutionary line from gothic rock to dream pop. Grow considered Julee Cruise's 1989 album Floating into the Night, written and produced by David Lynch and Angelo Badalamenti, as a significant development of the dream pop sound which \"gave the genre its synthy sheen.\" The influence of Cocteau Twins extended to the expansion of the genre's influence into Cantopop and Mandopop through the music of Faye Wong, who covered multiple Cocteau Twins songs, including tracks featured in Chungking Express, in which she also acted. Cocteau Twins would go on to collaborate with Wong on original songs of hers, and Wong contributed vocals to a limited release of a late Cocteau Twins single.\n",
    "\n",
    "In the early 1990s, some dream pop acts influenced by My Bloody Valentine, such as Seefeel, were drawn to techno and began utilizing elements such as samples and sequenced rhythms. Ambient pop music was described by AllMusic as \"essentially an extension of the dream pop that emerged in the wake of the shoegazer movement\", distinct for its incorporation of electronic textures.\n",
    "\n",
    "Much of the music associated with the 2009-coined term \"chillwave\" could be considered dream pop. In the opinion of Grantland's David Schilling, when \"chillwave\" was popularized, the discussion that followed among music journalists and bloggers revealed that labels such as \"shoegaze\" and \"dream pop\" were ultimately \"arbitrary and meaningless\".\"\"\",\n",
    "    \"\"\"North Ingria was located in the Karelian Isthmus, between Finland and Soviet Russia. It was established 23 January 1919. The republic was first served by a post office at the Rautu railway station on the Finnish side of the border. As the access across the border was mainly restricted, the North Ingrian postal service was finally launched in the early 1920. The man behind the idea was the lieutenant colonel Georg Elfvengren, head of the governing council of North Ingria. He was also known as an enthusiastic stamp collector. The post office was opened at the capital village of Kirjasalo.\n",
    "\n",
    "The first series of North Ingrian stamps were issued in 21 March 1920. They were based on the 1917 Finnish \"Model Saarinen\" series, a stamp designed by the Finnish architect Eliel Saarinen. The first series were soon sold to collectors, as the postage stamps became the major financial source of the North Ingrian government. The second series was designed for the North Ingrian postal service and issued 2 August 1920. The value of both series was in Finnish marks and similar to the postal fees of Finland. The number of letters sent from North Ingria was about 50 per day, most of them were carried to Finland. They were mainly sent by the personnel of the Finnish occupying forces. Large number of letters were also sent in pure philatelic purposes.\n",
    "\n",
    "With the Treaty of Tartu, the area was re-integrated into Soviet Russia and the use of the North Ingrian postage stamps ended in 4 December 1920. Stamps were still sold in Finland in 1921 with an overprinting \"Inkerin hyväksi\" (For the Ingria), but they were no longer valid. Funds of the sale went for the North Ingrian refugees.\"\"\",\n",
    "    \"\"\"Учитесь учиться! Мы вступаем в век, в котором образование, знания, профессиональные навыки будут определяющую роль в судьбе человека. Без знаний, кстати сказать, всё усложняющихся, просто нельзя будет работать, приносить пользу. Ибо физический труд возьмут на себя машины, роботы. Даже вычисления будут делаться компьютерами, так же как чертежи, расчёты, отчёты, планирование и т.д. Человек будет вносить новые идеи, думать над тем, над чем не сможет думать машина. А для этого всё больше нужна будет общая интеллигентность человека, его способность создавать новое и, конечно, нравственная ответственность, которую никак не сможет нести машина. Этика, простая в предшествующие века, бесконечно усложнится в век науки. Это ясно. Значит, на человека ляжет тяжелейшая и сложнейшая задача быть человеком не просто, а человеком науки, человеком, нравственно отвечающим за всё, что происходит в век машин и роботов. Общее образование может создать человека будущего, человека творческого, созидателя всего нового и нравственно за всё, что будет создаваться. Учение – вот что сейчас нужно молодому человеку с самого малого возраста. Учиться нужно всегда. До конца жизни не только учили, но и учились все крупнейшие учёные. Перестанешь учиться - не сможешь и учить. Ибо знания всё растут и усложняются. Нужно при этом помнить, что самое благоприятное время для учения – молодость. Именно в молодости, в детстве, в отрочестве, в юности ум человека наиболее восприимчив. Восприимчив к изучению языков (что крайне важно), к математике, к усвоению просто знаний и развитию эстетическому, стоящему рядом с развитием нравственным и отчасти его стимулирующим. Умейте не терять времени на пустяки, на «отдых», который иногда утомляет больше, чем самая тяжёлая работа, не заполняйте свой светлый разум мутными потоками глупой и бесцельной «информации». Берегите себя для учения, для приобретения знаний и навыков, которые только в молодости вы освоите легко быстро. И вот тут я слышу тяжкий вздох молодого человека: какую же скучную жизнь вы предлагаете нашей молодёжи! Только учиться. А где же отдых, развлечения? Что же нам, и не радоваться? Да нет же. Приобретение навыков и знаний – это тот же спорт. Учение тяжело, когда мы не умеем найти в нём радость. Надо уметь учиться и формы отдыха и развлечений выбирать умные, способные также чему-то научить, развить в нас какие-то способности, которые понадобятся в жизни. А если не нравится учиться? Быть того не может. Значит, вы просто не открыли той радости, которую приносит ребёнку, юноше, девушке приобретение знаний и навыков. Посмотрите на маленького ребёнка – с каким удовольствием он начинает учиться ходить, говорить, копаться в различных механизмах (у мальчиков), нянчить куклы (у девочек). Постарайтесь продолжить эту радость освоения нового. Это во многом зависит именно от вас самих. Не зарекайтесь: не люблю учиться! А вы попробуйте любить все предметы, какие проходите в школе. Если другим людям они нравятся, то почему вам они могут не понравиться! Читайте стоящие книги, а не просто чтиво. Изучайте историю и литературу. И то и другое должен хорошо знать интеллигентный человек. Именно они дают человеку нравственный и эстетический кругозор, делающий окружающий мир большим, интересным, излучающим опыт и радость. Если вам что-то не нравится в каком-то предмете – напрягитесь и постарайтесь найти в нём источник радости – радости приобретения нового. Учитесь любить учиться!\"\"\"\n",
    "]\n",
    "\n",
    "# Change these to wherever you want your inputs and outputs to go\n",
    "INPUT_FILE_PATH = \"inputs\"\n",
    "OUTPUT_FILE_PATH = \"outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пытался загружать текст из файла, \n",
    "\n",
    "но когда запускаю df = spark.createDataFrame(pd.DataFrame({'text': input_list})), выдает ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffУчитесь учиться!\\n\\n  Мы вступаем в век, в котором образование, знания, профессиональные навыки будут определяющую роль в судьбе человека. Без знаний, кстати сказать, всё усложняющихся, просто нельзя будет работать, приносить пользу. Ибо физический труд возьмут на себя машины, роботы. Даже вычисления будут делаться компьютерами, так же как чертежи, расчёты, отчёты, планирование и т.д. Человек будет вносить новые идеи, думать над тем, над чем не сможет думать машина. А для этого всё больше нужна будет общая интеллигентность человека, его способность создавать новое и, конечно, нравственная ответственность, которую никак не сможет нести машина. Этика, простая в предшествующие века, бесконечно усложнится в век науки. Это ясно.\\n  \\n  Значит, на человека ляжет тяжелейшая и сложнейшая задача быть человеком не просто, а человеком науки, человеком, нравственно отвечающим за всё, что происходит в век машин и роботов. Общее образование может создать человека будущего, человека творческого, созидателя всего нового и нравственно за всё, что будет создаваться.\\n  \\n  Учение – вот что сейчас нужно молодому человеку с самого малого возраста. Учиться нужно всегда. До конца жизни не только учили, но и учились все крупнейшие учёные. Перестанешь учиться - не сможешь и учить. Ибо знания всё растут и усложняются. Нужно при этом помнить, что самое благоприятное время для учения – молодость. Именно в молодости, в детстве, в отрочестве, в юности ум человека наиболее восприимчив. Восприимчив к изучению языков (что крайне важно), к математике, к усвоению просто знаний и развитию эстетическому, стоящему рядом с развитием нравственным и отчасти его стимулирующим.\\n  \\n  Умейте не терять времени на пустяки, на «отдых», который иногда утомляет больше, чем самая тяжёлая работа, не заполняйте свой светлый разум мутными потоками глупой и бесцельной «информации». Берегите себя для учения, для приобретения знаний и навыков, которые только в молодости вы освоите легко быстро.\\n  \\n  И вот тут я слышу тяжкий вздох молодого человека: какую же скучную жизнь вы предлагаете нашей молодёжи! Только учиться. А где же отдых, развлечения? Что же нам, и не радоваться?\\n  \\n  Да нет же. Приобретение навыков и знаний – это тот же спорт. Учение тяжело, когда мы не умеем найти в нём радость. Надо уметь учиться и формы отдыха и развлечений выбирать умные, способные также чему-то научить, развить в нас какие-то способности, которые понадобятся в жизни.\\n  \\n  А если не нравится учиться? Быть того не может. Значит, вы просто не открыли той радости, которую приносит ребёнку, юноше, девушке приобретение знаний и навыков.\\n  \\n  Посмотрите на маленького ребёнка – с каким удовольствием он начинает учиться ходить, говорить, копаться в различных механизмах (у мальчиков), нянчить куклы (у девочек). Постарайтесь продолжить эту радость освоения нового. Это во многом зависит именно от вас самих. Не зарекайтесь: не люблю учиться! А вы попробуйте любить все предметы, какие проходите в школе. Если другим людям они нравятся, то почему вам они могут не понравиться! Читайте стоящие книги, а не просто чтиво. Изучайте историю и литературу. И то и другое должен хорошо знать интеллигентный человек. Именно они дают человеку нравственный и эстетический кругозор, делающий окружающий мир большим, интересным, излучающим опыт и радость. Если вам что-то не нравится в каком-то предмете – напрягитесь и постарайтесь найти в нём источник радости – радости приобретения нового.\\n  \\n  Учитесь любить учиться!\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"inputs/Lihachev_learn.txt\", \"r\") as file:\n",
    "    input_list = file.read()\n",
    "input_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF1kBJ9vA9kx"
   },
   "source": [
    "Write the example inputs to the input folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "UITSel_Yr4IC"
   },
   "outputs": [],
   "source": [
    "! mkdir -p $INPUT_FILE_PATH\n",
    "\n",
    "for i, text in enumerate(input_list):\n",
    "    open(f'{INPUT_FILE_PATH}/Example{i + 1}.txt', 'w') \\\n",
    "        .write(text[:min(len(text) - 10, 100)] + '... \\n' + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0zS5R_7MV7T"
   },
   "source": [
    "## 3. Pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z7wW-eIMoN2"
   },
   "source": [
    "Create the NLP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "bpIz2L-bIO_Y"
   },
   "outputs": [],
   "source": [
    "# Transforms the raw text into a document readable by the later stages of the\n",
    "# pipeline\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "# Separates the document into sentences\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('sentences')# \\\n",
    "    #.setDetectLists(True)\n",
    "\n",
    "# Separates sentences into individial tokens (words)\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['sentences']) \\\n",
    "    .setOutputCol('tokens') \\\n",
    "    .setContextChars(['(', ')', '?', '!', '.', ','])\n",
    "\n",
    "# Модель извлечения ключевых фраз. Измените MinNGrams и MaxNGrams, \n",
    "# чтобы установить минимальную и максимальную длину возможных ключевых фраз, и \n",
    "# измените NKeywords, чтобы установить количество потенциальных ключевых фраз, идентифицированных в каждом документе.\n",
    "keywords = YakeModel() \\\n",
    "    .setInputCols('tokens') \\\n",
    "    .setOutputCol('keywords') \\\n",
    "    .setMinNGrams(2) \\\n",
    "    .setMaxNGrams(15) \\\n",
    "    .setNKeywords(1000) \\\n",
    "    .setStopWords(StopWordsCleaner().getStopWords())\n",
    "\n",
    "# Assemble all of these stages into a pipeline, then fit the pipeline on an\n",
    "# empty data frame so it can be used to transform new inputs.\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    keywords\n",
    "])\n",
    "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
    "pipeline_model = pipeline.fit(empty_df)\n",
    "\n",
    "# LightPipeline работает быстрее, чем Pipeline для небольших наборов данных\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZsaT1M_Mapv"
   },
   "source": [
    "## 4. Output creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InE4U2Fq-ih4"
   },
   "source": [
    "Служебные функции для создания более полезных наборов ключевых фраз из необработанного фрейма данных, создаваемого моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "xR7dJVA53qKK"
   },
   "outputs": [],
   "source": [
    "def adjusted_score(row, pow=2.5):\n",
    "    \"\"\"Эта функция настраивает оценки потенциальных ключевых фраз, чтобы дать лучшие\n",
    "    оценки фразам с большим количеством слов (которые, естественно, будут иметь худшие оценки\n",
    "    из-за природы модели). Вы можете изменить показатель, чтобы более или менее вознаграждать более длинные фразы. \n",
    "    Более высокие показатели вознаграждают более длинные фразы.\"\"\"\n",
    "    return ((row.result.count(' ') + 1) ** pow /\n",
    "            (float(row.metadata['score']) + 0.1))\n",
    "\n",
    "def get_top_ranges(phrases, input_text):\n",
    "    \"\"\"Комбинируйте фразы, которые накладываются друг на друга\"\"\"\n",
    "    starts = sorted([row['begin'] for row in phrases])\n",
    "    ends = sorted([row['end'] for row in phrases])\n",
    "\n",
    "    ranges = [[starts[0], None]]\n",
    "    for i in range(len(starts) - 1):\n",
    "        if ends[i] < starts[i + 1]:\n",
    "            ranges[-1][1] = ends[i]\n",
    "            ranges.append([starts[i + 1], None])\n",
    "    ranges[-1][1] = ends[-1]\n",
    "    return [{\n",
    "        'begin': range[0],\n",
    "        'end': range[1],\n",
    "        'phrase': input_text[range[0]:range[1] + 1]\n",
    "     } for range in ranges]\n",
    "\n",
    "def remove_duplicates(phrases):\n",
    "    \"\"\"Удалите фразы, которые появляются несколько раз.\"\"\"\n",
    "    i = 0\n",
    "    while i < len(phrases):\n",
    "        j = i + 1\n",
    "        while j < len(phrases):\n",
    "            if phrases[i]['phrase'] == phrases[j]['phrase']:\n",
    "                phrases.remove(phrases[j])\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    return phrases\n",
    "\n",
    "def get_output_lists(df_row):\n",
    "    \"\"\"Возвращает кортеж с двумя списками по 10 фраз в каждом. Первый объединяет ключевые фразы, \n",
    "    которые накладываются друг на друга, чтобы создать более длинные фразы, что лучше всего подходит для\n",
    "    выделения ключевых фраз в тексте, а второй - это просто ключевые фразы с самыми высокими баллами, \n",
    "    что лучше всего подходит для подведения итогов документа.\"\"\"\n",
    "    keyphrases = []\n",
    "    for row in df_row.keywords:\n",
    "        keyphrases.append({\n",
    "            'begin': row.begin,\n",
    "            'end': row.end,\n",
    "            'phrase': row.result,\n",
    "            'score': adjusted_score(row)\n",
    "        })\n",
    "    keyphrases = sorted(keyphrases, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    return (\n",
    "        get_top_ranges(keyphrases[:20], df_row.text)[:10],\n",
    "        remove_duplicates(keyphrases[:10])[:10]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9EswUu9-vPo"
   },
   "source": [
    "Преобразуйте входные данные примера для создания фрейма данных, хранящего идентифицированные ключевые фразы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "4YAV9JFfIO_f"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({'text': input_list}))\n",
    "result = light_pipeline.transform(df).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPQG2x_--3Ik"
   },
   "source": [
    "Для каждого примера создайте два файла JSON, содержащих выбор лучших ключевых фраз для документа. См. docstring get_output_lists две ячейки выше, чтобы узнать больше о двух созданных файлах JSON. Эти JSON-файлы используются непосредственно в публичном демонстрационном приложении для этой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "X-y9D7PRCiS8"
   },
   "outputs": [],
   "source": [
    "! mkdir -p $OUTPUT_FILE_PATH\n",
    "\n",
    "for i in range(len(result)):\n",
    "    top_ranges, top_summaries = get_output_lists(result.iloc[i])\n",
    "    with open(f'{OUTPUT_FILE_PATH}/Example{i + 1}.json', 'w') as ranges_file:\n",
    "        json.dump(top_ranges, ranges_file)\n",
    "    with open(f'{OUTPUT_FILE_PATH}/Example{i + 1}_summaries.json', 'w') \\\n",
    "            as summaries_file:\n",
    "        json.dump(top_summaries, summaries_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIJtDyaRI6hh"
   },
   "source": [
    "## 5. Visualize outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaZpx6SaJCBN"
   },
   "source": [
    "The raw pandas data frame containing the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "mzgZwqv9I6Cl",
    "outputId": "22e4a517-986d-454c-bd35-3f07065c7642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extracting keywords from texts has become a ch...</td>\n",
       "      <td>[(document, 0, 896, Extracting keywords from t...</td>\n",
       "      <td>[(document, 0, 135, Extracting keywords from t...</td>\n",
       "      <td>[(token, 0, 9, Extracting, {'sentence': '0'}, ...</td>\n",
       "      <td>[(keyword, 0, 18, extracting keywords, {'sente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iodine deficiency is a lack of the trace eleme...</td>\n",
       "      <td>[(document, 0, 1119, Iodine deficiency is a la...</td>\n",
       "      <td>[(document, 0, 90, Iodine deficiency is a lack...</td>\n",
       "      <td>[(token, 0, 5, Iodine, {'sentence': '0'}, []),...</td>\n",
       "      <td>[(keyword, 0, 16, iodine deficiency, {'sentenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Prague Quadrennial of Performance Design a...</td>\n",
       "      <td>[(document, 0, 1548, The Prague Quadrennial of...</td>\n",
       "      <td>[(document, 0, 287, The Prague Quadrennial of ...</td>\n",
       "      <td>[(token, 0, 2, The, {'sentence': '0'}, []), (t...</td>\n",
       "      <td>[(keyword, 4, 21, prague quadrennial, {'senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Author Nathan Wiseman-Trowse explained that th...</td>\n",
       "      <td>[(document, 0, 2358, Author Nathan Wiseman-Tro...</td>\n",
       "      <td>[(document, 0, 205, Author Nathan Wiseman-Trow...</td>\n",
       "      <td>[(token, 0, 5, Author, {'sentence': '0'}, []),...</td>\n",
       "      <td>[(keyword, 0, 12, author nathan, {'sentence': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North Ingria was located in the Karelian Isthm...</td>\n",
       "      <td>[(document, 0, 1679, North Ingria was located ...</td>\n",
       "      <td>[(document, 0, 83, North Ingria was located in...</td>\n",
       "      <td>[(token, 0, 4, North, {'sentence': '0'}, []), ...</td>\n",
       "      <td>[(keyword, 0, 11, north ingria, {'sentence': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Учитесь учиться! Мы вступаем в век, в котором ...</td>\n",
       "      <td>[(document, 0, 3425, Учитесь учиться! Мы вступ...</td>\n",
       "      <td>[(document, 0, 15, Учитесь учиться!, {'sentenc...</td>\n",
       "      <td>[(token, 0, 6, Учитесь, {'sentence': '0'}, [])...</td>\n",
       "      <td>[(keyword, 20, 29, вступаем в, {'sentence': '1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Extracting keywords from texts has become a ch...   \n",
       "1  Iodine deficiency is a lack of the trace eleme...   \n",
       "2  The Prague Quadrennial of Performance Design a...   \n",
       "3  Author Nathan Wiseman-Trowse explained that th...   \n",
       "4  North Ingria was located in the Karelian Isthm...   \n",
       "5  Учитесь учиться! Мы вступаем в век, в котором ...   \n",
       "\n",
       "                                            document  \\\n",
       "0  [(document, 0, 896, Extracting keywords from t...   \n",
       "1  [(document, 0, 1119, Iodine deficiency is a la...   \n",
       "2  [(document, 0, 1548, The Prague Quadrennial of...   \n",
       "3  [(document, 0, 2358, Author Nathan Wiseman-Tro...   \n",
       "4  [(document, 0, 1679, North Ingria was located ...   \n",
       "5  [(document, 0, 3425, Учитесь учиться! Мы вступ...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [(document, 0, 135, Extracting keywords from t...   \n",
       "1  [(document, 0, 90, Iodine deficiency is a lack...   \n",
       "2  [(document, 0, 287, The Prague Quadrennial of ...   \n",
       "3  [(document, 0, 205, Author Nathan Wiseman-Trow...   \n",
       "4  [(document, 0, 83, North Ingria was located in...   \n",
       "5  [(document, 0, 15, Учитесь учиться!, {'sentenc...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [(token, 0, 9, Extracting, {'sentence': '0'}, ...   \n",
       "1  [(token, 0, 5, Iodine, {'sentence': '0'}, []),...   \n",
       "2  [(token, 0, 2, The, {'sentence': '0'}, []), (t...   \n",
       "3  [(token, 0, 5, Author, {'sentence': '0'}, []),...   \n",
       "4  [(token, 0, 4, North, {'sentence': '0'}, []), ...   \n",
       "5  [(token, 0, 6, Учитесь, {'sentence': '0'}, [])...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [(keyword, 0, 18, extracting keywords, {'sente...  \n",
       "1  [(keyword, 0, 16, iodine deficiency, {'sentenc...  \n",
       "2  [(keyword, 4, 21, prague quadrennial, {'senten...  \n",
       "3  [(keyword, 0, 12, author nathan, {'sentence': ...  \n",
       "4  [(keyword, 0, 11, north ingria, {'sentence': '...  \n",
       "5  [(keyword, 20, 29, вступаем в, {'sentence': '1...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'begin': 1544, 'end': 1551, 'phrase': 'знаний и', 'score': 17.8511658567772},\n",
       " {'begin': 2549, 'end': 2556, 'phrase': 'знаний и', 'score': 17.8511658567772},\n",
       " {'begin': 3073, 'end': 3078, 'phrase': 'и то и', 'score': 17.811434810617737},\n",
       " {'begin': 29, 'end': 33, 'phrase': 'в век', 'score': 15.03738309174792},\n",
       " {'begin': 888, 'end': 892, 'phrase': 'в век', 'score': 15.03738309174792},\n",
       " {'begin': 1880,\n",
       "  'end': 1895,\n",
       "  'phrase': 'знаний и навыков',\n",
       "  'score': 14.171712113699739},\n",
       " {'begin': 3023,\n",
       "  'end': 3033,\n",
       "  'phrase': 'а не просто',\n",
       "  'score': 12.260118911125272}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('outputs/Example6_summaries.json', 'r', encoding='utf-8') as f: #открыли файл с данными\n",
    "    text_sum = json.load(f) #загнали все, что получилось в переменную\n",
    "\n",
    "text_sum #вывели результат на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EbaXFSRJX8s"
   },
   "source": [
    "Список верхних ключевых фраз (с перекрывающимися объединенными ключевыми фразами) для последнего примера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### почему остались повторы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5j9LTWLJI_L",
    "outputId": "32e1b4d9-ff29-49f1-f926-bfe5854ceb4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'begin': 29, 'end': 33, 'phrase': 'в век'},\n",
       " {'begin': 706, 'end': 710, 'phrase': 'в век'},\n",
       " {'begin': 801, 'end': 809, 'phrase': 'не просто'},\n",
       " {'begin': 888, 'end': 900, 'phrase': 'в век машин и'},\n",
       " {'begin': 1239, 'end': 1250, 'phrase': 'не сможешь и'},\n",
       " {'begin': 1537, 'end': 1551, 'phrase': 'просто знаний и'},\n",
       " {'begin': 1880, 'end': 1895, 'phrase': 'знаний и навыков'},\n",
       " {'begin': 2111, 'end': 2125, 'phrase': 'и не радоваться'},\n",
       " {'begin': 2549, 'end': 2564, 'phrase': 'знаний и навыков'},\n",
       " {'begin': 3023, 'end': 3033, 'phrase': 'а не просто'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SrNEDaOJl6V"
   },
   "source": [
    "Список лучших сводных ключевых фраз (с удаленными дубликатами) для последнего примера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### как фраза 'и то и' могла набрать большую оценку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0I68Le1JM_8",
    "outputId": "f26acab6-fafb-4025-d0f0-b384b4510f69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'begin': 3073, 'end': 3078, 'phrase': 'и то и', 'score': 28.533519923176826},\n",
       " {'begin': 1544,\n",
       "  'end': 1551,\n",
       "  'phrase': 'знаний и',\n",
       "  'score': 21.27200525476634},\n",
       " {'begin': 2549,\n",
       "  'end': 2556,\n",
       "  'phrase': 'знаний и',\n",
       "  'score': 21.27200525476634},\n",
       " {'begin': 1880,\n",
       "  'end': 1895,\n",
       "  'phrase': 'знаний и навыков',\n",
       "  'score': 19.19131032447267},\n",
       " {'begin': 1239,\n",
       "  'end': 1250,\n",
       "  'phrase': 'не сможешь и',\n",
       "  'score': 17.74329543860378},\n",
       " {'begin': 2111,\n",
       "  'end': 2125,\n",
       "  'phrase': 'и не радоваться',\n",
       "  'score': 17.393712971631714},\n",
       " {'begin': 29, 'end': 33, 'phrase': 'в век', 'score': 17.355679151169674}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KEYPHRASE_EXTRACTION.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
